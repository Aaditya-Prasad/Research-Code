{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\n#%matplotlib inline\nimport argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport pandas as pd\nfrom IPython.display import HTML","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\n#test = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n#sub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n#print(train.head())\n#train_label = train.loc[:, 'healthy':].values\n\nhealthy = train['healthy'].values\nmultiple_diseases = train['multiple_diseases'].values\nrust = train['rust'].values\nscab = train['scab'].values\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir healthy multiple_diseases rust scab","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir healthy/images scab/images multiple_diseases/images rust/images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport shutil \n# first arg for shutil.copy() is the file to copy, second is where u want to copy into (you'll prob need to change the file you want to copy)\nfor i in range(train['image_id'].values.size):\n    if healthy[i] == 1:\n        shutil.copy(f'/kaggle/input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg', f'healthy/images/Train_{i}.jpg')\n    if scab[i] == 1:\n        shutil.copy(f'/kaggle/input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg', f'scab/images/Train_{i}.jpg')\n    if rust[i] == 1:\n        shutil.copy(f'/kaggle/input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg', f'rust/images/Train_{i}.jpg')\n    if multiple_diseases[i] == 1:\n        shutil.copy(f'/kaggle/input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg', f'multiple_diseases/images/Train_{i}.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seed for reproducibility\nmanualSeed = 999\nmanualSeed = random.randint(1, 10000) # use if you want new results\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    # move tensors to a device\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\ndevice = get_default_device()\ndevice\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Number of workers for dataloader\nworkers = 2\n\n# Batch size during training\nbatch_size = 32\n\n# Spatial size of training images. All images will be resized to this\n#   size using a transformer.\nimage_size = 64\n\n# Number of channels in the training images. For color images this is 3\nnc = 3\n\n# Size of z latent vector (i.e. size of generator input)\nnz = 100\n\n# Size of feature maps in generator\nngf = 64\n\n# Size of feature maps in discriminator\nndf = 64\n\n# Number of training epochs\nnum_epochs = 150\n# Learning rate for optimizers\nlr = 0.0002\n\n# Beta1 hyperparam for Adam optimizers\nbeta1 = 0.5\n\n# Number of GPUs available. Use 0 for CPU mode.\nngpu = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dset.ImageFolder(root='healthy',\n                           transform=transforms.Compose([\n                               transforms.Resize(image_size),\n                               transforms.CenterCrop(image_size),\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n                           ]))\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n                                         shuffle=True, num_workers=workers)\nreal_batch = next(iter(dataloader))\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\nlen(dataloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, ngpu):\n        super(Generator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        return self.main(input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"netG = Generator(ngpu).to(device)\n\nnetG.apply(weights_init)\n\nprint(netG)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, ngpu):\n        super(Discriminator, self).__init__()\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input nc x 64 x 64\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnetD = Discriminator(ngpu).to(device)\n\nnetD.apply(weights_init)\n\nprint(netD)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using BCEloss\ncriterion = nn.BCELoss()\nfixed_noise = torch.randn(64, nz, 1, 1, device=device)\nreal = 1.\nfake = 0.\n\noptimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training Loop\n\nimg_list = []\nG_losses = []\nD_losses = []\niters = 0\n\nprint(\"Starting Training Loop...\")\n#train the discriminator twice everytime G is trained once to prevent mode collapse\nfor epoch in range(num_epochs):\n    for i, data in enumerate(dataloader, 0):\n        \n        #Discriminator training\n        #all real batch\n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real, dtype=torch.float, device=device)\n        output = netD(real_cpu).view(-1)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        #all fake batch\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n        \n        \n        netD.zero_grad()\n        real_cpu = data[0].to(device)\n        b_size = real_cpu.size(0)\n        label = torch.full((b_size,), real, dtype=torch.float, device=device)\n        output = netD(real_cpu).view(-1)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        #train fake again\n        noise = torch.randn(b_size, nz, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n                \n\n        #Generator training\n        netG.zero_grad()\n        label.fill_(real)  # fake labels are real for generator cost\n        output = netD(fake).view(-1)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        # Output training stats\n        if i % 50 == 0:\n            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n                  % (epoch, num_epochs, i, len(dataloader),\n                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        # sample generators work on fixed noise \n        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n            with torch.no_grad():\n                fake = netG(fixed_noise).detach().cpu()\n            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n\n        iters += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%capture\nfig = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\nani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n\n\nHTML(ani.to_jshtml())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir output4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import save_image\n# with torch.no_grad():\n#     random_noise = torch.randn(100, nz, 1, 1, device=device)\n#     fake = netG(fixed_noise).detach().cpu()\nfor i in range(1000):\n    with torch.no_grad():\n        random_noise = torch.randn(1, nz, 1, 1, device=device)\n        fake = netG(random_noise).detach().cpu()\n    img = fake[0]\n    save_image(img, f'output4/trainsynthetic_{i}.png')\n    if(i % 100 == 0):\n        print(f\"done with {i}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, shutil\ndef make_archive(source, destination):\n        base = os.path.basename(destination)\n        name = base.split('.')[0]\n        format = base.split('.')[1]\n        archive_from = os.path.dirname(source)\n        archive_to = os.path.basename(source.strip(os.sep))\n        print(source, destination, archive_from, archive_to)\n        shutil.make_archive(name, format, archive_from, archive_to)\n        shutil.move('%s.%s'%(name,format), destination)\n\nmake_archive('./output4', 'build.zip')\n\nprint(\"done with zip\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nxvals = range(0, 2550)\nplt.plot(xvals, G_losses, label = \"Generator Loss\")\n\nplt.plot(xvals, D_losses, label = \"Discriminator Loss\")\nplt.xlabel('Training Cycle')\nplt.ylabel('Loss')\nplt.title('GAN Training Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}